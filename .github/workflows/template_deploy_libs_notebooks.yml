name: deploy

on:
  workflow_call:
    inputs:
      runs-on:
        description: Platform to execute on
        type: string
        default: ubuntu-latest
      env:
        description: Environment deploy to
        type: string
        default: DEV
      DATABRICKS_NOTEBOOK_PATH:
        description: Location where notebooks will be deployed in Databricks
        type: string
        default: /Shared/notebook-tests/dbxbuild_${{github.run_number}}/     

jobs:
  deploy-libs-notebooks:
    runs-on: ${{ inputs.runs-on }}
    environment: ${{ inputs.env }}

    steps:
    - name: Download Artifacts
      uses: dawidd6/action-download-artifact@v2
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        workflow: notebook-github-ci.yml
        name: artifacts
    - name: setup python 3.8
      uses: actions/setup-python@v3
      with:
        python-version: "3.8"
        architecture: "x64"        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -e .     
        pip install databricks-cli
    - name: Upload libs to Databricks
      run: |
        echo "Uploading libs at ./libs to workspace dbfs:/lib-dist ..."
        databricks fs mkdirs dbfs:/lib-dist
        databricks fs cp "./libs" dbfs:/lib-dist --recursive --overwrite
      env:
        DATABRICKS_HOST: ${{ secrets.databricksDomain }}
        DATABRICKS_TOKEN: ${{ secrets.databricksToken }}
    - name: Install libs in Databricks
      run: |
        echo "Installing libs dbfs:/lib-dist ..."
        for file in `databricks fs ls dbfs:/lib-dist --absolute`
        do
            extension="${file##*.}"
            if [ $extension = "whl" ]
            then
                echo "Installing libs $file ..."
                databricks libraries install --cluster-id $CLUSTER --whl $file
            fi
        done
      env:
        DATABRICKS_HOST: ${{ secrets.databricksDomain }}
        DATABRICKS_TOKEN: ${{ secrets.databricksToken }}
        CLUSTER: ${{ secrets.databricksClusterId }}
    - name: Deploy notebooks
      run: |
        echo "Uploading notebooks at ./notebook_jobs to workspace ${{ inputs.DATABRICKS_NOTEBOOK_PATH }} ..."
        databricks workspace import_dir --overwrite "./notebook_jobs" "${{ inputs.DATABRICKS_NOTEBOOK_PATH }}"
      env:
        DATABRICKS_HOST: ${{ secrets.databricksDomain }}
        DATABRICKS_TOKEN: ${{ secrets.databricksToken }}
        DATABRICKS_NOTEBOOK_PATH: ${{ inputs.databricksNotebookPath }}